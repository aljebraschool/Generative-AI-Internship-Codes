{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aljebraschool/Generative-AI-Internship-Codes/blob/main/Prompt_Engineering_practice_questions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZngKarjT7JQH",
        "outputId": "82888111-68e4-4fde-9488-20abfd1cc8fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.23.3-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.5/311.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.23.3\n"
          ]
        }
      ],
      "source": [
        "#install openai package\n",
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5mrLhjS3Md3"
      },
      "outputs": [],
      "source": [
        "#import needed libraries\n",
        "from api_key import api_key #import api_key python file\n",
        "import os #import operating system for directory\n",
        "from openai import Client #import Client class from openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMms4oTDLI2s"
      },
      "source": [
        "### Using model for chat completion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoUPZJkEw1IU",
        "outputId": "01e4b861-84a5-46fc-aebb-43883b7fc077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the world of code, a tale unfolds,\n",
            "Of a concept profound, where beauty holds.\n",
            "Recursion it's called, a mystical art,\n",
            "A dance of function, a work of heart.\n",
            "\n",
            "Like a mirror reflecting its own grace,\n",
            "A function calls itself in a seamless embrace.\n",
            "Infinite loops, an elegant dance,\n",
            "Each call a chance, a new romance.\n",
            "\n",
            "With each recursive step, the problem divides,\n",
            "Solving small pieces, in clever strides.\n",
            "A fractal of logic, unfolding wide,\n",
            "In the endless loop, where mysteries hide.\n",
            "\n",
            "But beware, young programmer, of a perilous snare,\n",
            "Infinite recursion, a nightmare to bear.\n",
            "With base cases forgotten, in the code's deep lair,\n",
            "The stack overflows, in a crash so unfair.\n",
            "\n",
            "So understand recursion, wield it with care,\n",
            "A powerful tool, with a touch so rare.\n",
            "A symphony of code, a rhythm to share,\n",
            "In the programmer's world, where dreams declare.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize the OpenAI client\n",
        "client = Client()\n",
        "\n",
        "# Define the messages for chat completion\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
        "]\n",
        "\n",
        "# Create the chat completion\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "#print the content of the model response\n",
        "print(completion.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wed6C0iLVHn"
      },
      "source": [
        "### Using model for conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po_BqpVoyF5-",
        "outputId": "27ea5504-7680-4506-a3fe-b9c080be38ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "client = Client()\n",
        "messages = [{'role': 'user', 'content': 'Hello World!!!'}]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo',\n",
        "    messages = messages\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3vV4_xW6i9o",
        "outputId": "9edc49f7-37b4-4341-b3ea-9a6ba9fe51d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Space complexity is a measure of the amount of memory space an algorithm requires to solve a problem as a function of the input size. It evaluates how much additional memory is needed by an algorithm in terms of the input size.\n",
            "\n",
            "Similar to time complexity, space complexity is expressed using Big O notation to describe the upper bound on the amount of memory used by an algorithm as the input size grows. It helps determine how efficient an algorithm is in terms of memory usage.\n",
            "\n",
            "Just like optimizing for time complexity, it is also important to optimize for space complexity in order to create more efficient algorithms.\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {'role': 'system', 'content': 'You are a helpful teacher'},\n",
        "    {'role': 'user', 'content': 'Is there any other measure than time complexity for an algorithm?'},\n",
        "    {'role': 'assistant', 'content': 'Yes, there is also space complexity'},\n",
        "    {'role': 'user', 'content': 'Oh!, then explain that!'},\n",
        "\n",
        "]\n",
        "\n",
        "client = Client(api_key = 'sk-proj-7D36Bcar5sgEvnby6wzCT3BlbkFJhkpSk2ySMxuwjUdJKCdc')\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo',\n",
        "    messages = messages,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4fodXsRKVVH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcWhKDAqhyimIfmdW5pXqt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}